{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH2pJNqf9HY7kIM2YN4Q5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahidhamidi/ML-Project/blob/main/Testing_Pre_trained_Model_Binary_False_Positive_Case_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJTmRVfsfmn8",
        "outputId": "82215bcb-718f-47a6-c5a3-40b81bc5bc49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.12.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.14.0\n",
            "GPU is NOT AVAILABLE\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import re\n",
        "import spacy\n",
        "from gensim import corpora, models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the CSV file\n",
        "csv_file_path = '/content/true_positive_experimentation.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the text data from the 'text' column\n",
        "text_data = df['doc_text_original'].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxQD0Mprfoi-",
        "outputId": "716fdd00-0b79-47c1-bdbc-493b5bc47e51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-96e57bab995a>:5: DtypeWarning: Columns (1,2,3,4,5,10,15,16,17,21,22,30,32,34,35,36,37,40,43,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        # Handle non-string elements here, for example, by returning an empty string\n",
        "        return \"\"\n",
        "\n",
        "    # Remove special characters using regular expressions\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Filter out non-string elements from text_data and preprocess the rest\n",
        "preprocessed_data = [preprocess_text(text) for text in text_data if isinstance(text, str)]"
      ],
      "metadata": {
        "id": "MI2PkTrzmq9L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization of text data\n",
        "# tokenized_data = [text.split() for text in preprocessed_data]"
      ],
      "metadata": {
        "id": "LMoapllUncsN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with pre-trained model\n",
        "\n",
        "# Load the pre-trained model from TensorFlow Hub\n",
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "# embedding = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=False)\n",
        "\n",
        "# Flatten and join the tokenized data into a single string for each document\n",
        "X_test = [\" \".join(doc) for doc in preprocessed_data]\n",
        "\n",
        "# Create a binary classification model by adding a dense layer with sigmoid activation\n",
        "model = tf.keras.Sequential([\n",
        "    hub_layer,\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Load pre-trained weights (if available)\n",
        "# model.load_weights(\"path_to_pretrained_weights.h5\")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Make predictions on your test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Assuming predictions are probability scores, you can threshold them to get binary predictions\n",
        "binary_predictions = (predictions > 0.5).astype(np.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBEqtXqzngCm",
        "outputId": "fe38109f-dfe5-4656-c571-b49622ee797b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'binary_predictions' contains your binary predictions\n",
        "# Ensure that the length of 'binary_predictions' matches the number of rows you want to update\n",
        "num_rows_to_update = len(binary_predictions)\n",
        "\n",
        "# Update the \"predicted_label_code\" column with the binary predictions for the first 'num_rows_to_update' rows\n",
        "df.loc[:num_rows_to_update - 1, 'predicted_label_code'] = binary_predictions\n",
        "\n",
        "# Now, 'df' should have the \"predicted_label_code\" column filled with the predictions for the specified number of rows\n"
      ],
      "metadata": {
        "id": "NZSWA-VTniCo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have loaded your DataFrame 'df' with the columns 'label_code' and 'predicted_label_code'\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (df['label_code'] == df['predicted_label_code']).sum()\n",
        "total_predictions = len(preprocessed_data)\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(f\"Number of correct predictions: {correct_predictions}\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaJyv_WUo-wa",
        "outputId": "f68ccfc4-9818-488a-8e07-6d45a080657e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of correct predictions: 27\n",
            "Accuracy: 29.03%\n"
          ]
        }
      ]
    }
  ]
}