{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+W6Z7Dg5TQ6a12PHbE9He",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahidhamidi/ML-Project/blob/main/Training_NLP_false_positive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6orFXzig8Ru"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Clear the TensorFlow session and reset the computational graph\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Assuming you already have your 'balanced_df' DataFrame\n",
        "\n",
        "# Separate the data into two DataFrames based on the label_code\n",
        "df_class_0 = balanced_df[balanced_df[\"label_code\"] == 0]\n",
        "df_class_1 = balanced_df[balanced_df[\"label_code\"] == 1]\n",
        "\n",
        "# Shuffle the DataFrames\n",
        "df_class_0 = shuffle(df_class_0, random_state=42)\n",
        "df_class_1 = shuffle(df_class_1, random_state=42)\n",
        "\n",
        "# Split each class into train, validation, and test sets\n",
        "train_frac = 0.6\n",
        "val_frac = 0.2\n",
        "\n",
        "# Split class 0\n",
        "train_size_class_0 = int(train_frac * len(df_class_0))\n",
        "val_size_class_0 = int(val_frac * len(df_class_0))\n",
        "\n",
        "train_class_0 = df_class_0[:train_size_class_0]\n",
        "val_class_0 = df_class_0[train_size_class_0:train_size_class_0 + val_size_class_0]\n",
        "test_class_0 = df_class_0[train_size_class_0 + val_size_class_0:]\n",
        "\n",
        "# Split class 1\n",
        "train_size_class_1 = int(train_frac * len(df_class_1))\n",
        "val_size_class_1 = int(val_frac * len(df_class_1))\n",
        "\n",
        "train_class_1 = df_class_1[:train_size_class_1]\n",
        "val_class_1 = df_class_1[train_size_class_1:train_size_class_1 + val_size_class_1]\n",
        "test_class_1 = df_class_1[train_size_class_1 + val_size_class_1:]\n",
        "\n",
        "# Concatenate the balanced train, validation, and test sets\n",
        "train_df = pd.concat([train_class_0, train_class_1])\n",
        "val_df = pd.concat([val_class_0, val_class_1])\n",
        "test_df = pd.concat([test_class_0, test_class_1])\n",
        "\n",
        "# Shuffle the combined DataFrames\n",
        "train_df = shuffle(train_df, random_state=42)\n",
        "val_df = shuffle(val_df, random_state=42)\n",
        "test_df = shuffle(test_df, random_state=42)\n",
        "\n",
        "# Extract examples and labels from the split DataFrames\n",
        "train_examples = train_df[\"doc_text_original\"]\n",
        "train_labels = train_df[\"label_code\"]\n",
        "\n",
        "val_examples = val_df[\"doc_text_original\"]\n",
        "val_labels = val_df[\"label_code\"]\n",
        "\n",
        "test_examples = test_df[\"doc_text_original\"]\n",
        "test_labels = test_df[\"label_code\"]\n",
        "\n",
        "# Now you have balanced train, validation, and test sets with equal distribution of classes.\n"
      ],
      "metadata": {
        "id": "ZNFJHZf_hAH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=False)"
      ],
      "metadata": {
        "id": "hY_FU673hAPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tRvZKA7hhAXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])"
      ],
      "metadata": {
        "id": "s2cJK8ERhEJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "history = model.fit(\n",
        "    x = train_examples,  # Training data\n",
        "    y = train_labels,  # Training labels\n",
        "    epochs=40,           # Number of training epochs\n",
        "    batch_size=512,      # Batch size\n",
        "    validation_data=(val_examples, val_labels),  # Validation data\n",
        "    verbose=1            # Verbosity level (0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
        ")"
      ],
      "metadata": {
        "id": "xDJQy3KQhERX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_examples, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "n2vRfNPEhEZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "id": "zF4xxekDhEgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QQqD-AI4hLLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1CjQAyVYhLRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming your model has already been trained and evaluated as you mentioned\n",
        "\n",
        "# Make predictions on the test data\n",
        "predicted_labels = model.predict(test_examples)\n",
        "\n",
        "# Convert the predicted probabilities to binary labels (0 or 1)\n",
        "predicted_labels_binary = np.argmax(predicted_labels, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion = confusion_matrix(test_labels, predicted_labels_binary)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', square=True, xticklabels=True, yticklabels=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Calculate additional evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, predicted_labels_binary)\n",
        "precision = precision_score(test_labels, predicted_labels_binary)\n",
        "recall = recall_score(test_labels, predicted_labels_binary)\n",
        "f1 = f1_score(test_labels, predicted_labels_binary)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "0_0NsVf-hNb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already made predictions on your test data as mentioned earlier\n",
        "\n",
        "# Create a DataFrame with the original text, true labels, and predicted labels\n",
        "results_df = pd.DataFrame({'doc_text_original': test_examples, 'label_code': test_labels, 'predicted_label': predicted_labels_binary})\n",
        "\n"
      ],
      "metadata": {
        "id": "ciBDSI-LhQvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "results_df"
      ],
      "metadata": {
        "id": "fN0wIyeShSZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}